name: dq-repair

on:
  schedule:
    # Incremental every 2 days @ 03:20 UTC
    - cron: "20 3 */2 * *"
    # Monthly full pass on the 1st @ 04:15 UTC
    - cron: "15 4 1 * *"
  workflow_dispatch:
    inputs:
      DRY_RUN:
        description: "Dry run (no writes) 0/1"
        required: false
        default: "0"
      VERBOSE:
        description: "Verbose logs 0/1"
        required: false
        default: "0"
      BACKFILL_DAILY_FROM_API:
        description: "Use API to fill missing daily 0/1"
        required: false
        default: "1"
      SEED_10M_FROM_DAILY:
        description: "Seed synthetic 10m from daily 0/1"
        required: false
        default: "0"
      TOP_N_DQ:
        description: "Max coins to scan (blank=default)"
        required: false
        default: ""
      DQ_MAX_API_COINS_PER_RUN:
        description: "API backfills per run (cap)"
        required: false
        default: "20"
      # NEW toggles you might want to flip via UI
      FULL_MODE:
        description: "Full aggregate recompute 0/1"
        required: false
        default: "0"
      TRUNCATE_AGGREGATES_IN_FULL:
        description: "TRUNCATE agg tables before full recompute 0/1"
        required: false
        default: "1"
      RECOMPUTE_MCAP_10M:
        description: "Recompute 10m aggregates 0/1"
        required: false
        default: "1"
      RECOMPUTE_MCAP_HOURLY:
        description: "Recompute hourly aggregates 0/1"
        required: false
        default: "1"
      RECOMPUTE_MCAP_DAILY:
        description: "Recompute daily aggregates 0/1"
        required: false
        default: "1"
      FULL_DAILY_ALL:
        description: "Full-table daily aggregate (2013â†’now) 0/1 (use for one-time rebuild)"
        required: false
        default: "0"

permissions:
  contents: read

concurrency:
  group: dq-repair
  cancel-in-progress: true

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 35
    env:
      TZ: UTC
      PYTHONUNBUFFERED: "1"
      PYTHONUTF8: "1"
      PYTHONWARNINGS: "ignore::DeprecationWarning"
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: "requirements.txt"

      - name: Install dependencies
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install "cassandra-driver==3.29.0" requests python-dotenv tzdata
          # If you keep astra_connect as a local module, PYTHONPATH=.
          # If it's a package on PyPI/private index, install it here instead.

      - name: Export PYTHONPATH (repo root)
        run: echo "PYTHONPATH=." >> "$GITHUB_ENV"

      - name: Write Astra secure connect bundle
        run: |
          set -euo pipefail
          echo "${{ secrets.ASTRA_BUNDLE_BASE64 }}" | base64 -d > secure-connect.zip
          test -s secure-connect.zip || { echo "secure-connect.zip missing/empty"; exit 1; }
          ls -lh secure-connect.zip

      - name: Data Quality & Repair (incremental vs full decided by schedule)
        timeout-minutes: 25
        env:
          ASTRA_BUNDLE_PATH: secure-connect.zip
          ASTRA_TOKEN: ${{ secrets.ASTRA_TOKEN }}
          ASTRA_KEYSPACE: ${{ secrets.ASTRA_KEYSPACE }}
          COINGECKO_API_TIER: ${{ secrets.COINGECKO_API_TIER != '' && secrets.COINGECKO_API_TIER || 'pro' }}
          COINGECKO_API_KEY: ${{ secrets.COINGECKO_API_KEY }}

          # Source tables
          TABLE_LIVE: "gecko_prices_live"
          TEN_MIN_TABLE: "gecko_prices_10m_7d"
          DAILY_TABLE: "gecko_candles_daily_contin"
          HOURLY_TABLE: "gecko_candles_hourly_30d"
          TABLE_ROLLING: "gecko_prices_live_rolling"

          # Aggregate target tables (defaults already match these names; keep for clarity)
          MCAP_10M_TABLE: "gecko_market_cap_10m_7d"
          MCAP_HOURLY_TABLE: "gecko_market_cap_hourly_30d"
          MCAP_DAILY_TABLE: "gecko_market_cap_daily_contin"

          # Universe + windows
          TOP_N_DQ: ${{ github.event.inputs.TOP_N_DQ != '' && github.event.inputs.TOP_N_DQ || '110' }}
          DQ_MAX_COINS: "210"
          DQ_WINDOW_10M_DAYS: "7"
          DQ_WINDOW_DAILY_DAYS: "365"
          DQ_WINDOW_HOURLY_DAYS: "30"

          # Existing repair knobs
          FIX_DAILY_FROM_10M: "1"
          BACKFILL_DAILY_FROM_API: ${{ github.event.inputs.BACKFILL_DAILY_FROM_API || '1' }}
          SEED_10M_FROM_DAILY: ${{ github.event.inputs.SEED_10M_FROM_DAILY || '0' }}
          DQ_DRY_RUN: ${{ github.event.inputs.DRY_RUN || '0' }}

          DQ_MAX_API_COINS_PER_RUN: ${{ github.event.inputs.DQ_MAX_API_COINS_PER_RUN || '20' }}
          DAILY_API_MAX_RANGE_DAYS: "90"
          DAILY_API_PAD_DAYS: "1"

          # Timeouts, pacing
          DQ_REQUEST_TIMEOUT_SEC: "30"
          DQ_CONNECT_TIMEOUT_SEC: "15"
          DQ_FETCH_SIZE: "500"
          DQ_RETRIES: "3"
          DQ_BACKOFF_SEC: "4"
          DQ_PAUSE_PER_COIN: "0.2"

          # Logging (NEW: richer heartbeats/slow-query warnings)
          DQ_LOG_HEARTBEAT_SEC: "15"
          DQ_LOG_EVERY_TS: "10"
          DQ_LOG_EVERY_COIN: "25"
          DQ_LOG_FETCH_EVERY_ROWS: "5000"
          DQ_SLOW_QUERY_WARN_SEC: "5"

          DQ_LOG_EVERY: "10"
          DQ_VERBOSE: ${{ github.event.inputs.VERBOSE || '0' }}
          DQ_TIME_API: "1"

          # Aggregate recompute toggles
          # Decide FULL vs INCREMENTAL based on schedule: monthly full, otherwise incremental.
          FULL_MODE: ${{ (github.event_name == 'schedule' && startsWith(github.event.schedule, '15 4 1')) && '1' || (github.event.inputs.FULL_MODE || '0') }}
          TRUNCATE_AGGREGATES_IN_FULL: ${{ github.event.inputs.TRUNCATE_AGGREGATES_IN_FULL || '1' }}
          RECOMPUTE_MCAP_10M: ${{ github.event.inputs.RECOMPUTE_MCAP_10M || '1' }}
          RECOMPUTE_MCAP_HOURLY: ${{ github.event.inputs.RECOMPUTE_MCAP_HOURLY || '1' }}
          RECOMPUTE_MCAP_DAILY: ${{ github.event.inputs.RECOMPUTE_MCAP_DAILY || '1' }}

          # Daily full-table rebuild (ONE-TIME or manual)
          # Leave "0" for normal monthly runs; trigger with workflow_dispatch to run one-time.
          FULL_DAILY_ALL: ${{ github.event.inputs.FULL_DAILY_ALL || '0' }}

          # Soft budget to fit in the job timeout
          DQ_SOFT_BUDGET_SEC: "1500" # 25 minutes

        run: |
          set -euo pipefail
          python prices/FF_gck_dq_repair_timeseries.py
